{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g036R7Uxrser"
   },
   "source": [
    "# Introduction\n",
    "This notebook serves as an example for the process of the analysis of semantic similarity. Semantic similarity requires not simply comparing text, but comparing what the text is supposed to mean. Even people can have disagreements over this, so computing something that abstract is a complex task.\n",
    "\n",
    "A concept of vital importance is text embedding. Text is relatively hard to compare; comparing numbers is significantly faster than comparing strings, the latter possibly requiring iterating over each character to check it. Transforming the text into a numerical representation brings a lot of efficiency, and is an important first step. There are multiple ways to go about this.\n",
    "\n",
    "The simplest way is called <i>bag of words</i>. The entire vocabulary of the library of text we want to compare is numerically allocated; each word is given an entry in a simple lookup table. A sentence can then be vectorized, each vector being the same length as the lookup table, and each index holding the count of how often the word assigned that number appears in the sentence. Comparing these vectors then essentially compares the overlap between words used in sentences, assuming that the same words lead to the same meanings.\n",
    "\n",
    "Of course, as the 'bag' implies, we lose order, a very important part of semantic meaning. Additionally, words may be functionally similar, but be different counts; two sentences each using different synonyms would be very different in this theory. 'Greater' could be stemmed to 'great', but the same is harder for 'better' and 'good'. What about 'terrific' and 'great'? We could look up synonyms for each word, but this quickly becomes very inefficient. Then there's the question of how relevant a word is; a 'I have a good book' is very different from a 'I have a good car', after all, despite being 80% \"similar\".\n",
    "\n",
    "This relevancy problem can be diminished using TFIDF, or term frequency–inverse document frequency, to introduce a weighting. The more often a term shows up in a document, which is any arbitrary amount of text, the more relevant it is. The more documents that term shows up in, however, the less relevant. The sentences above may be reduced to 'good book' and 'good car', for example, based on the exact implementation. \n",
    "\n",
    "A more complex solution is to use a continuous bag of words such as described in the Word2Vec model as originally patented by Google, an implementation of which exists in the open source Gensim package. The concept is similar to a normal bag of words, but instead of each word apart, we look at the surrounding words. Each word is paired with its surroundings, creating a structure that allows for the prediction of words: using the above sentences again, 'good' can predict 'a', 'book', or 'car'. Then, TFIDF could be applied to determine the odds of predicting each word, or these weights can be determined more accurately using a neural network, as described in the original article. The Gensim package uses the latter method. The (abstracted) weights can be vectorized, and these are then used much like the simpler embedding can be.\n",
    "\n",
    "To compare sentences, the embedded word vector can be taken for each word in the sentence, taking the average. Two averaged vectors can then be compared to determine how similar they are. This solves the relevancy and synonym problems, but does not preserve order; some context from sentence structure is lost. An expansion on the Word2Vec method, the Doc2Vec method, designed by the same authors, proposes to solve this by taking the word vectors in a document, and adding a 'phantom word'; the resulting so called document vector is then unique for that document, in an attempt to remember or at least account for the entire document context. This also has an implementation built in Gensim.\n",
    "\n",
    "How long the resulting vector is, depends on the implementation. The Gensim implementations use a vector size of 100 by default. Larger vectors can capture more details, but make computation more expensive. In our case, 100 was an apt choice \n",
    "\n",
    "In the next cell, we load versions of these three models trained on the data provided to us, to show their capability. Additionally, a pretrained Google model known as the Universal Sentence Encoder will be shown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIVLxlq95zJj"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1T5i1sHW9DPk"
   },
   "outputs": [],
   "source": [
    "from process import readdata, preprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "arWXvpQR5s1F",
    "outputId": "46b680e2-8863-44cf-bacc-426ac41b0883"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the story of kohinoor (koh-i-noor) dia...</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>why am i mentally very lonely? how can i solve...</td>\n",
       "      <td>find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>astrology: i am a capricorn sun cap moon and c...</td>\n",
       "      <td>i'm a triple capricorn (sun, moon and ascendan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>should i buy tiago?</td>\n",
       "      <td>what keeps childern active and far from phone ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>how can i be a good geologist?</td>\n",
       "      <td>what should i do to be a great geologist?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>when do you use シ instead of し?</td>\n",
       "      <td>when do you use \"&amp;\" instead of \"and\"?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>motorola (company): can i hack my charter moto...</td>\n",
       "      <td>how do i hack motorola dcx3400 for free internet?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  what is the step by step guide to invest in sh...   \n",
       "1   1     3     4  what is the story of kohinoor (koh-i-noor) dia...   \n",
       "2   2     5     6  how can i increase the speed of my internet co...   \n",
       "3   3     7     8  why am i mentally very lonely? how can i solve...   \n",
       "4   4     9    10  which one dissolve in water quikly sugar, salt...   \n",
       "5   5    11    12  astrology: i am a capricorn sun cap moon and c...   \n",
       "6   6    13    14                                should i buy tiago?   \n",
       "7   7    15    16                     how can i be a good geologist?   \n",
       "8   8    17    18                    when do you use シ instead of し?   \n",
       "9   9    19    20  motorola (company): can i hack my charter moto...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  what is the step by step guide to invest in sh...             0  \n",
       "1  what would happen if the indian government sto...             0  \n",
       "2  how can internet speed be increased by hacking...             0  \n",
       "3  find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            which fish would survive in salt water?             0  \n",
       "5  i'm a triple capricorn (sun, moon and ascendan...             1  \n",
       "6  what keeps childern active and far from phone ...             0  \n",
       "7          what should i do to be a great geologist?             1  \n",
       "8              when do you use \"&\" instead of \"and\"?             0  \n",
       "9  how do i hack motorola dcx3400 for free internet?             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = readdata.read()\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "9j860lzR8s_2",
    "outputId": "cbe64243-acea-4338-fb2b-ac1cdcd65511"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['is_duplicate'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "MdBLt2926886",
    "outputId": "5cd36e4e-df7b-4b6e-e98f-230c879e1326"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[what, is, the, step, by, step, guide, to, inv...</td>\n",
       "      <td>[what, is, the, step, by, step, guide, to, inv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[what, is, the, story, of, kohinoor, koh, i, n...</td>\n",
       "      <td>[what, would, happen, if, the, indian, governm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>[how, can, i, increase, the, speed, of, my, in...</td>\n",
       "      <td>[how, can, internet, speed, be, increased, by,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>[why, am, i, mentally, very, lonely, how, can,...</td>\n",
       "      <td>[find, the, remainder, when, math, 23, 24, mat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>[which, one, dissolve, in, water, quikly, suga...</td>\n",
       "      <td>[which, fish, would, survive, in, salt, water]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>[astrology, i, am, a, capricorn, sun, cap, moo...</td>\n",
       "      <td>[i'm, a, triple, capricorn, sun, moon, and, as...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>[should, i, buy, tiago]</td>\n",
       "      <td>[what, keeps, childern, active, and, far, from...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>[how, can, i, be, a, good, geologist]</td>\n",
       "      <td>[what, should, i, do, to, be, a, great, geolog...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>[when, do, you, use, シ, instead, of, し]</td>\n",
       "      <td>[when, do, you, use, instead, of, and]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>[motorola, company, can, i, hack, my, charter,...</td>\n",
       "      <td>[how, do, i, hack, motorola, dcx3400, for, fre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  [what, is, the, step, by, step, guide, to, inv...   \n",
       "1   1     3     4  [what, is, the, story, of, kohinoor, koh, i, n...   \n",
       "2   2     5     6  [how, can, i, increase, the, speed, of, my, in...   \n",
       "3   3     7     8  [why, am, i, mentally, very, lonely, how, can,...   \n",
       "4   4     9    10  [which, one, dissolve, in, water, quikly, suga...   \n",
       "5   5    11    12  [astrology, i, am, a, capricorn, sun, cap, moo...   \n",
       "6   6    13    14                            [should, i, buy, tiago]   \n",
       "7   7    15    16              [how, can, i, be, a, good, geologist]   \n",
       "8   8    17    18            [when, do, you, use, シ, instead, of, し]   \n",
       "9   9    19    20  [motorola, company, can, i, hack, my, charter,...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  [what, is, the, step, by, step, guide, to, inv...             0  \n",
       "1  [what, would, happen, if, the, indian, governm...             0  \n",
       "2  [how, can, internet, speed, be, increased, by,...             0  \n",
       "3  [find, the, remainder, when, math, 23, 24, mat...             0  \n",
       "4     [which, fish, would, survive, in, salt, water]             0  \n",
       "5  [i'm, a, triple, capricorn, sun, moon, and, as...             1  \n",
       "6  [what, keeps, childern, active, and, far, from...             0  \n",
       "7  [what, should, i, do, to, be, a, great, geolog...             1  \n",
       "8             [when, do, you, use, instead, of, and]             0  \n",
       "9  [how, do, i, hack, motorola, dcx3400, for, fre...             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = preprocess.clean_process(data)\n",
    "clean_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuamSHKmrsex"
   },
   "source": [
    "# Embedding Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train embeddings \n",
    "run_w2v.py takes 3 minutes to train, while run_d2v.py takes 40 minutes to train. For time saving, run_d2v.py is off by default. In order to see the results of the d2v model, run run_d2v.py once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Reading data ---\n",
      "--- Training model ---\n",
      "W2V Model saved.\n"
     ]
    }
   ],
   "source": [
    "%run run_w2v.py\n",
    "# %run run_d2v.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NnM514CCrse0"
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec, doc2vec\n",
    "import pickle\n",
    "from embed import universal_sentence_encoder as use_model\n",
    "\n",
    "# Load the pretrained models\n",
    "w2v_model = word2vec.Word2Vec.load(\"models/w2vmodel.mod\")\n",
    "w2v_vectors = w2v_model.wv\n",
    "\n",
    "try:\n",
    "    d2v_model = doc2vec.Doc2Vec.load(\"models/d2v/doc2vec.model\")\n",
    "except:\n",
    "    d2v_model = 0\n",
    "    \n",
    "tfidf_NB = pickle.load(open(\"models/vectorizer_NB.p\", \"rb\"))\n",
    "tfidf_cosine = pickle.load(open(\"models/vectorizer_cosine.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1rfQncwrse2"
   },
   "source": [
    "# Classification\n",
    "\n",
    "The above models and instruction clarify how to embed text, acquiring vectors for the relevant documents. It mentions comparing these vectors, but not exactly how. There are, again, multiple ways to do this. The simplest way is to calculate the cosine similarity between them, essentially imagining we have position vectors, and checking the angle between them. This is relatively easy to compute, intuitive, and gives a result between 0 and 1, making it very easy to use; set or train a proper threshold, and if the cosine similarity is above that threshold, the sentences carry the same semantic intent.\n",
    "\n",
    "A complexer but significantly more accurate way of comparing is through the use of a neural network. Starting with more-or-less random predictions, the correct answers are used to calculate how wrong the network's prediction was, which is then used to update it, improving the next prediction. Through repetition, the network thus learns how to tell which vectors are supposed to be 'similar', learning to classify them. We implemented a relatively simple neural network, that takes as input two concatenated vectors; the two sentence vectors we want to compare. One hidden layer, of equal size to the input layer, with as activation function the rectified linear activation function, and finally a sigmoid function for the output layer of size 1. This output is simply a 0 or 1, signifying whether the sentences are the same or not.\n",
    "\n",
    "The training of this second method is rather computationally expensive, though training doesn't necessarily have happen more than once. However, it also requires a large amount of annotated data; a large list of sentence combinations of which it is known if they are semantically the same or not. Additionally, this data should be very varied, as scenarios not adequately present in the training data will be hard to predict. This data being accurate is also of vital importance for accuracy, meaning it will have to be done, or at least verified, by hand. Our data consisted of about 400000 pairs of questions, meaning the network is likely to be better at classifying questions than other sentence structures. While this machine learning is not applicable in every situation, the prerequisites are something to keep in mind.\n",
    "\n",
    "Below we load our pretrained models, after which the requirements for analysis are present, and some examples can be run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBYCVOl-rse3"
   },
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YlgbdlyYrse3"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from classifiers import binaryclassification as bc\n",
    "from embed import w2vec, doc2vec, d2vec\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from scipy import spatial\n",
    "import tensorflow as tf\n",
    "import importlib\n",
    "\n",
    "# Load the pretrained models\n",
    "w2v_network = keras.models.load_model('neuralnets/w2v.h5')\n",
    "d2v_network = keras.models.load_model('neuralnets/d2v.h5')\n",
    "use_network = keras.models.load_model('neuralnets/use.h5')\n",
    "NB_classifier = pickle.load(open(\"neuralnets/NB_classifier.pickle\", \"rb\"))\n",
    "tokenizer = RegexpTokenizer(r'\\w+\\'*\\w*')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f54Qez9DoVUc"
   },
   "source": [
    "# Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "iNFx7ORzcncg"
   },
   "outputs": [],
   "source": [
    "def predict_models(text1, text2):\n",
    "    tokens1 = tokenizer.tokenize(text1.lower())\n",
    "    tokens2 = tokenizer.tokenize(text2.lower())\n",
    "\n",
    "    ''' Preprocessing '''\n",
    "    print('Preprocessing:')\n",
    "    d = {'sentence':[tokens1, tokens2]}\n",
    "    pd.set_option('display.max_colwidth',None)\n",
    "    display(pd.DataFrame(data=d, index=['s1','s2']))\n",
    "\n",
    "    ''' Vectorize '''\n",
    "    w2v_vector = np.array([bc.vectorize_w2v(w2v_vectors, tokens1, tokens2)])\n",
    "    if d2v_model == 0:\n",
    "        d2v_vector = 0\n",
    "        print('Results for D2V are turned off')\n",
    "    else:\n",
    "        d2v_vector = np.array([d2vec.doc2vec(d2v_model, tokens1, tokens2)])\n",
    "        print('Results for D2v are turned on')\n",
    "    use_vector = tf.convert_to_tensor(np.array(tf.concat([use_model.encode(text1), use_model.encode(text2)], axis=0)).reshape((1, 1024)))\n",
    "    tfidf_NB_vector = tfidf_NB.transform([text1+text2])\n",
    "    tfidf_cosine_vector = tfidf_cosine.transform([text1, text2])\n",
    "\n",
    "    ''' Create list of classifier predictions '''\n",
    "    classifier_preds = []\n",
    "    classifier_preds.append((w2v_network.predict(w2v_vector) > 0.5).astype(\"int32\")[0][0] == 1)\n",
    "    if isinstance(d2v_vector, int):\n",
    "        classifier_preds.append(False)\n",
    "    else:\n",
    "        classifier_preds.append((d2v_network.predict(d2v_vector) > 0.5).astype(\"int32\")[0][0] == 1)\n",
    "    classifier_preds.append((use_network.predict(use_vector) > 0.5).astype(\"int32\")[0][0] == 1)\n",
    "    classifier_preds.append(NB_classifier.predict(tfidf_NB_vector)[0] == 1)\n",
    "\n",
    "    ''' Create list of cosine predictions '''\n",
    "    cosine_preds = []\n",
    "    cosine_preds.append(w2vec.string_similarity(w2v_model, tokens1, tokens2) > 0.98)\n",
    "    if isinstance(d2v_vector, int):\n",
    "        cosine_preds.append(False)\n",
    "    else:\n",
    "        cosine_preds.append((1 - spatial.distance.cosine(d2v_vector[0][:100], d2v_vector[0][100:])) > 0.98)\n",
    "    cosine_preds.append((1 - spatial.distance.cosine(use_vector[0][:512], use_vector[0][512:])) > 0.98)\n",
    "    cosine_preds.append(((tfidf_cosine_vector * tfidf_cosine_vector.T).A)[0,1] > 0.98)\n",
    "\n",
    "    ''' Combine predictions '''\n",
    "    preds = []\n",
    "    preds.append(classifier_preds)\n",
    "    preds.append(cosine_preds)\n",
    "\n",
    "    ''' Create Dataframe '''\n",
    "    df = pd.DataFrame(preds, index=['Classifier','Cosine'], columns=['W2V','D2V','USE','TFIDF'])\n",
    "    print('\\n\\nPredictions:')\n",
    "    return df\n",
    "\n",
    "def on_butt_clicked(b):\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        display(predict_models(sentence1.value, sentence2.value))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ESkRKIO_khr"
   },
   "source": [
    "# Run Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471,
     "referenced_widgets": [
      "58aafce498024dc79881eaef11e67a63",
      "c5fa0e1381be4f1781717555c47168a0",
      "66467ffdd3e141c593fe57435d25b516",
      "60139df3f77b4a36bf82a6c158753ef9",
      "097b08dd57854c158e31f64af0fdf5f8",
      "83df4764825b4df295344f70ff902f58",
      "ee5fb2e74d5d4b988eb62b455301af73",
      "3e4e6a8bee414f83920071b04c39a0da",
      "d5ad26820e204aa08a5c521751966e63",
      "5ced3fc006094e56a1319b6fd5fc9987"
     ]
    },
    "id": "YZJVrMoarse6",
    "outputId": "16a9853e-38a8-469e-ccd3-234553435d25"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35fb34eea1124d8da153d63d5d5d3dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='What is the best programming language to learn?', description='sentence1', layout=Layout(heigh…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90efb3abac4a407ab140d877516770a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='Which programming languages are considered to be the best?', description='sentence2', layout=L…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad4fd3f82f64f59b9aeb5d0b3198329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='predict', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "110287b56d604fea8ff3ccb5fe572236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l = widgets.Layout(height = '80px', width='500px')\n",
    "\n",
    "sentence1 = widgets.Textarea(description = 'sentence1', value = \"What is the best programming language to learn?\", layout = l)\n",
    "sentence2 = widgets.Textarea(description = 'sentence2', value = \"Which programming languages are considered to be the best?\", layout = l)\n",
    "submit =  widgets.Button(description=\"predict\")\n",
    "out = widgets.Output()\n",
    "\n",
    "submit.on_click(on_butt_clicked)\n",
    "\n",
    "display(sentence1, sentence2, submit, out)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "_KinVozCAbj5"
   ],
   "name": "Example_Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "097b08dd57854c158e31f64af0fdf5f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3e4e6a8bee414f83920071b04c39a0da": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "58aafce498024dc79881eaef11e67a63": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "TextareaModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextareaModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextareaView",
      "continuous_update": true,
      "description": "sentence1",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_c5fa0e1381be4f1781717555c47168a0",
      "placeholder": "​",
      "rows": null,
      "style": "IPY_MODEL_66467ffdd3e141c593fe57435d25b516",
      "value": "What is the best programming language to learn?"
     }
    },
    "5ced3fc006094e56a1319b6fd5fc9987": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60139df3f77b4a36bf82a6c158753ef9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "TextareaModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextareaModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextareaView",
      "continuous_update": true,
      "description": "sentence2",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_c5fa0e1381be4f1781717555c47168a0",
      "placeholder": "​",
      "rows": null,
      "style": "IPY_MODEL_097b08dd57854c158e31f64af0fdf5f8",
      "value": "Which programming languages are considered to be the best?"
     }
    },
    "66467ffdd3e141c593fe57435d25b516": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "83df4764825b4df295344f70ff902f58": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "predict",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_ee5fb2e74d5d4b988eb62b455301af73",
      "style": "IPY_MODEL_3e4e6a8bee414f83920071b04c39a0da",
      "tooltip": ""
     }
    },
    "c5fa0e1381be4f1781717555c47168a0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": "80px",
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "500px"
     }
    },
    "d5ad26820e204aa08a5c521751966e63": {
     "model_module": "@jupyter-widgets/output",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_5ced3fc006094e56a1319b6fd5fc9987",
      "msg_id": "",
      "outputs": [
       {
        "metadata": {
         "tags": []
        },
        "output_type": "stream",
        "stream": "stdout",
        "text": "Preprocessing:\n"
       },
       {
        "metadata": {
         "tags": []
        },
        "output_type": "display_data",
        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>s1</th>\n      <td>[what, is, the, best, programming, language, to, learn]</td>\n    </tr>\n    <tr>\n      <th>s2</th>\n      <td>[which, programming, languages, are, considered, to, be, the, best]</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
        "text/plain": "                                                               sentence\ns1              [what, is, the, best, programming, language, to, learn]\ns2  [which, programming, languages, are, considered, to, be, the, best]"
       },
       {
        "metadata": {
         "tags": []
        },
        "output_type": "stream",
        "stream": "stdout",
        "text": "\n\nPredictions:\n"
       },
       {
        "metadata": {
         "tags": []
        },
        "output_type": "display_data",
        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>W2V</th>\n      <th>D2V</th>\n      <th>USE</th>\n      <th>TFIDF</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Classifier</th>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>Cosine</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
        "text/plain": "              W2V    D2V    USE  TFIDF\nClassifier   True  False   True   True\nCosine      False  False  False  False"
       }
      ]
     }
    },
    "ee5fb2e74d5d4b988eb62b455301af73": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
